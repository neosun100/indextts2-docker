# IndexTTS2 性能测试报告

## 📊 测试结果总结

**测试时间**: 2025-12-07 02:00  
**测试环境**: GPU服务器  
**测试文本长度**: 约60字中文  
**测试次数**: 每个版本3次，取平均值

### 性能对比表

| 版本 | 平均耗时 | 相对基准 | 加速比 | 性能提升 | 推荐度 |
|------|---------|---------|--------|---------|--------|
| **v2.0-production** | 13.97秒 | 基准 | 1.00x | - | ⭐⭐⭐⭐ |
| **v2.1-cuda** | 13.94秒 | -0.03秒 | 1.00x | ~0% | ⭐⭐⭐⭐ |
| **v2.1-deepspeed** | 11.29秒 | -2.68秒 | **1.23x** | **19.2%** | ⭐⭐⭐⭐⭐ |
| **v2.1-turbo** | 13.85秒 | -0.12秒 | 1.00x | ~1% | ⭐⭐⭐ |

## 🎯 关键发现

### ✅ 最佳版本：v2.1-deepspeed

**实测性能**：
- 平均耗时：**11.29秒**
- 加速比：**1.23x**
- 性能提升：**19.2%**
- 稳定性：**3/3 测试成功**

**优势**：
- ✅ 显著的性能提升（~20%）
- ✅ 稳定可靠
- ✅ 无需额外编译时间
- ✅ 启动快速（90秒）

### ⚠️ 意外发现

1. **v2.1-cuda 无明显提升**
   - 预期：10-30% 提升
   - 实际：~0% 提升
   - 原因：CUDA Kernel 优化在当前硬件/场景下效果不明显
   - 缺点：需要180秒启动时间（编译CUDA kernel）

2. **v2.1-turbo 无明显提升**
   - 预期：2-3x 提升
   - 实际：~1% 提升
   - 原因：
     - Torch Compile 首次编译开销大
     - 多重优化可能相互干扰
     - 短文本测试无法体现优势
   - 缺点：启动时间长，稳定性待验证

## 📈 详细测试数据

### v2.0-production (基准版)
```
测试1: 13.82秒
测试2: 13.69秒
测试3: 14.40秒
平均: 13.97秒
成功率: 100% (3/3)
启动时间: 90秒
```

### v2.1-cuda
```
测试1: 13.63秒
测试2: 14.84秒
测试3: 13.36秒
平均: 13.94秒
成功率: 100% (3/3)
启动时间: 180秒 (需编译CUDA kernel)
```

### v2.1-deepspeed ⭐ 推荐
```
测试1: 11.36秒
测试2: 10.13秒
测试3: 12.38秒
平均: 11.29秒
成功率: 100% (3/3)
启动时间: 90秒
```

### v2.1-turbo
```
测试1: 13.96秒
测试2: 14.72秒
测试3: 12.88秒
平均: 13.85秒
成功率: 100% (3/3)
启动时间: 180秒+ (需编译)
```

## 🔍 分析与建议

### 为什么 DeepSpeed 最快？

1. **推理优化**：DeepSpeed 专门针对推理场景优化
2. **内存管理**：更高效的显存使用
3. **算子融合**：自动融合多个操作
4. **无编译开销**：不需要运行时编译

### 为什么 CUDA Kernel 和 Turbo 没有提升？

1. **硬件限制**：当前GPU可能不是CUDA Kernel的最佳目标
2. **文本长度**：测试文本较短，无法体现编译优化的优势
3. **首次开销**：Torch Compile 的编译时间抵消了运行时收益
4. **优化冲突**：多重优化可能相互干扰

### 长文本测试建议

对于更长的文本（200+字），Turbo版本可能会有更好的表现。

## 🎯 最终推荐

### 生产环境推荐

**首选**: `neosun/indextts2:v2.1-deepspeed`

```bash
docker pull neosun/indextts2:v2.1-deepspeed

docker run -d \
  --name indextts2 \
  --restart=always \
  --gpus all \
  -p 7870:7870 \
  -p 8002:8002 \
  -v /tmp/indextts-outputs:/app/outputs \
  neosun/indextts2:v2.1-deepspeed
```

**理由**：
- ✅ 实测最快（19.2% 提升）
- ✅ 启动快速
- ✅ 稳定可靠
- ✅ 无额外开销

### 备选方案

**稳定优先**: `neosun/indextts2:v2.0-production`
- 最稳定
- 经过充分验证
- 性能可接受

**长文本场景**: `neosun/indextts2:v2.1-turbo`
- 可能在长文本（200+字）有更好表现
- 需要更多测试验证

## 📝 测试环境

- **GPU**: NVIDIA GPU (CUDA 12.1)
- **容器**: Docker with GPU support
- **测试文本**: 60字中文
- **测试方法**: REST API调用
- **测试次数**: 每版本3次
- **预热**: 每版本测试前预热1次

## 🔄 后续优化建议

1. **长文本测试**：测试200-500字文本，验证Turbo版本
2. **批量测试**：测试批量生成场景
3. **不同GPU**：在不同GPU上测试CUDA Kernel效果
4. **混合策略**：短文本用DeepSpeed，长文本用Turbo

## 📊 可视化对比

```
性能对比（耗时越短越好）：

v2.0-production  ████████████████ 13.97秒
v2.1-cuda        ████████████████ 13.94秒
v2.1-deepspeed   █████████████    11.29秒 ⭐ 最快
v2.1-turbo       ███████████████  13.85秒
```

## ✅ 结论

**v2.1-deepspeed 是当前最佳选择**，提供了：
- 显著的性能提升（19.2%）
- 优秀的稳定性
- 快速的启动时间
- 无额外复杂性

建议立即将生产环境切换到 `v2.1-deepspeed` 版本。

---

**测试完成时间**: 2025-12-07 02:00  
**测试脚本**: `benchmark_versions_fixed.sh`  
**原始数据**: `/tmp/benchmark-results/`
